name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  release:
    types: [ published ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: universal-data-stack
  KUBE_NAMESPACE: universal-data-stack
  KUBE_CONTEXT: production

jobs:
  # Test Job
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        node-version: [18.x, 20.x]
        service: [api-gateway, auth-service, data-service, search-service, notification-service, analytics-service]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'
        cache-dependency-path: microservices/${{ matrix.service }}/package-lock.json

    - name: Install dependencies
      run: |
        cd microservices/${{ matrix.service }}
        npm ci

    - name: Run linting
      run: |
        cd microservices/${{ matrix.service }}
        npm run lint

    - name: Run tests
      run: |
        cd microservices/${{ matrix.service }}
        npm test -- --coverage --watchAll=false

    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: microservices/${{ matrix.service }}/coverage/lcov.info
        flags: ${{ matrix.service }}
        name: ${{ matrix.service }}-coverage

  # Security Scan Job
  security:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'

    - name: Upload Trivy scan results
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'

    - name: Run npm audit
      run: |
        find . -name "package.json" -not -path "./node_modules/*" | while read file; do
          dir=$(dirname "$file")
          echo "Auditing $dir"
          cd "$dir"
          npm audit --audit-level=moderate
          cd - > /dev/null
        done

  # Build Job
  build:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: [test, security]
    if: github.event_name == 'push' || github.event_name == 'release'
    
    strategy:
      matrix:
        service: [api-gateway, auth-service, data-service, search-service, notification-service, analytics-service, event-bus]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ github.repository }}/${{ matrix.service }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=semver,pattern={{version}}
          type=semver,pattern={{major}}.{{minor}}
          type=sha,prefix={{branch}}-

    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: ./microservices/${{ matrix.service }}
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        platforms: linux/amd64,linux/arm64

  # Deploy to Staging
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/develop'
    environment: staging
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure kubectl
      uses: azure/k8s-set-context@v3
      with:
        method: kubeconfig
        kubeconfig: ${{ secrets.KUBE_CONFIG_STAGING }}

    - name: Deploy to staging
      run: |
        helm upgrade --install universal-data-stack-staging ./k8s/helm-charts/universal-data-stack \
          --namespace staging \
          --create-namespace \
          --set image.tag=${{ github.sha }} \
          --set image.registry=${{ env.REGISTRY }} \
          --set ingress.hosts[0].host=staging-api.universaldata.local \
          --values ./k8s/helm-charts/universal-data-stack/values-staging.yaml

    - name: Wait for deployment
      run: |
        kubectl rollout status deployment/universal-data-stack-staging-api-gateway -n staging --timeout=300s

    - name: Run smoke tests
      run: |
        kubectl get pods -n staging
        kubectl get services -n staging

  # Deploy to Production
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/main' || github.event_name == 'release'
    environment: production
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure kubectl
      uses: azure/k8s-set-context@v3
      with:
        method: kubeconfig
        kubeconfig: ${{ secrets.KUBE_CONFIG_PRODUCTION }}

    - name: Deploy to production
      run: |
        helm upgrade --install universal-data-stack ./k8s/helm-charts/universal-data-stack \
          --namespace production \
          --create-namespace \
          --set image.tag=${{ github.sha }} \
          --set image.registry=${{ env.REGISTRY }} \
          --set ingress.hosts[0].host=api.universaldata.local \
          --values ./k8s/helm-charts/universal-data-stack/values-production.yaml

    - name: Wait for deployment
      run: |
        kubectl rollout status deployment/universal-data-stack-api-gateway -n production --timeout=600s

    - name: Run health checks
      run: |
        kubectl get pods -n production
        kubectl get services -n production
        
        # Wait for services to be ready
        kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=universal-data-stack -n production --timeout=300s

    - name: Run integration tests
      run: |
        # Get service URL
        SERVICE_URL=$(kubectl get service universal-data-stack-api-gateway -n production -o jsonpath='{.status.loadBalancer.ingress[0].ip}')
        
        # Run integration tests against the deployed service
        curl -f http://$SERVICE_URL/health || exit 1
        curl -f http://$SERVICE_URL/api/health || exit 1

  # Rollback Job
  rollback:
    name: Rollback Deployment
    runs-on: ubuntu-latest
    if: failure() && (github.ref == 'refs/heads/main' || github.event_name == 'release')
    environment: production
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Configure kubectl
      uses: azure/k8s-set-context@v3
      with:
        method: kubeconfig
        kubeconfig: ${{ secrets.KUBE_CONFIG_PRODUCTION }}

    - name: Rollback deployment
      run: |
        kubectl rollout undo deployment/universal-data-stack-api-gateway -n production
        kubectl rollout status deployment/universal-data-stack-api-gateway -n production --timeout=300s

    - name: Notify rollback
      uses: 8398a7/action-slack@v3
      with:
        status: failure
        text: "Deployment rollback completed for ${{ github.repository }}"
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

  # Cleanup Job
  cleanup:
    name: Cleanup
    runs-on: ubuntu-latest
    needs: [deploy-staging, deploy-production]
    if: always()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Clean up old images
      run: |
        # Remove images older than 30 days
        echo "Cleaning up old Docker images..."
        # This would typically be done by the container registry's retention policy

    - name: Clean up old deployments
      run: |
        # Clean up old Helm releases
        echo "Cleaning up old Helm releases..."
        # This would depend on your Helm setup and retention policy